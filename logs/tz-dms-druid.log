[druid] 2018-08-17 00:32:11,906 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-08-17 00:32:11,906 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-08-17 00:32:12,015 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-08-17 00:32:12,062 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-08-17 00:32:12,062 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Cleaning up the staging area file:/tmp/hadoop-Administrator/mapred/staging/hadoop1269547057/.staging/job_local1269547057_0001
   [druid] 2018-08-17 00:32:12,062 [main           ] WARN  .security.UserGroupInformation {1} - PriviledgedActionException as:hadoop (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory E:/test/out/004 already exists
   [druid] 2018-08-17 00:32:41,052 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-08-17 00:32:41,052 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-08-17 00:32:41,161 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-08-17 00:32:41,223 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-08-17 00:32:41,223 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-08-17 00:32:42,986 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1493738988_0001
   [druid] 2018-08-17 00:32:42,986 [Thread-17      ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-08-17 00:32:43,002 [Thread-17      ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-08-17 00:32:43,049 [Thread-17      ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-08-17 00:32:43,049 [pool-1-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1493738988_0001_m_000000_0
   [druid] 2018-08-17 00:32:43,095 [pool-1-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-08-17 00:32:43,142 [pool-1-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-08-17 00:32:43,158 [pool-1-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/E:/test/testdata/access.log:0+4718
   [druid] 2018-08-17 00:32:43,173 [pool-1-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-08-17 00:32:43,173 [pool-1-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-08-17 00:32:43,283 [pool-1-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-08-17 00:32:43,283 [pool-1-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-08-17 00:32:43,329 [pool-1-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-08-17 00:32:43,329 [pool-1-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-08-17 00:32:43,439 [pool-1-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-08-17 00:32:43,470 [pool-1-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1493738988_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-08-17 00:32:43,485 [pool-1-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-08-17 00:32:43,485 [pool-1-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1493738988_0001_m_000000_0' done.
   [druid] 2018-08-17 00:32:43,485 [pool-1-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1493738988_0001_m_000000_0
   [druid] 2018-08-17 00:32:43,485 [Thread-17      ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-08-17 00:32:43,517 [Thread-17      ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-08-17 00:32:43,532 [Thread-17      ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-08-17 00:32:43,532 [Thread-17      ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-08-17 00:32:43,548 [Thread-17      ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-08-17 00:32:43,579 [Thread-17      ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6218 bytes
   [druid] 2018-08-17 00:32:43,579 [Thread-17      ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-08-17 00:32:43,969 [Thread-17      ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1493738988_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-08-17 00:32:43,985 [Thread-17      ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-08-17 00:32:43,985 [Thread-17      ] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1493738988_0001_r_000000_0 is allowed to commit now
   [druid] 2018-08-17 00:32:44,000 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-08-17 00:32:44,000 [Thread-17      ] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1493738988_0001_r_000000_0' to E:/test/out/004
   [druid] 2018-08-17 00:32:44,000 [Thread-17      ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-08-17 00:32:44,000 [Thread-17      ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1493738988_0001_r_000000_0' done.
   [druid] 2018-08-17 00:32:45,014 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-08-17 00:32:45,014 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1493738988_0001
   [druid] 2018-08-17 00:32:45,030 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 17
   [druid] 2018-08-17 00:32:45,030 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-08-17 00:32:45,030 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=15966
   [druid] 2018-08-17 00:32:45,030 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=351196
   [druid] 2018-08-17 00:32:45,030 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-08-17 00:32:45,030 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-08-17 00:32:45,030 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-08-17 00:32:45,030 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-08-17 00:32:45,030 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=46
   [druid] 2018-08-17 00:32:45,030 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=46
   [druid] 2018-08-17 00:32:45,030 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=6092
   [druid] 2018-08-17 00:32:45,030 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=98
   [druid] 2018-08-17 00:32:45,045 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-08-17 00:32:45,045 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-08-17 00:32:45,045 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=46
   [druid] 2018-08-17 00:32:45,045 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-08-17 00:32:45,045 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=46
   [druid] 2018-08-17 00:32:45,045 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=46
   [druid] 2018-08-17 00:32:45,045 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=92
   [druid] 2018-08-17 00:32:45,045 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=458227712
   [druid] 2018-08-17 16:42:06,386 [main           ] WARN  f.etl.mr.tohbase.TohbaseRunner {1} - 设置作业的输入路径异常.
   java.net.ConnectException: Call From PC201807051736/10.0.16.15 to hadoop701:9000 failed on connection exception: java.net.ConnectException: Connection refused: no further information; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1441)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at com.sun.proxy.$Proxy11.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:786)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:258)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)
	at com.sun.proxy.$Proxy12.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:2145)
	at org.apache.hadoop.hdfs.DistributedFileSystem$20.doCall(DistributedFileSystem.java:1265)
	at org.apache.hadoop.hdfs.DistributedFileSystem$20.doCall(DistributedFileSystem.java:1261)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1261)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1418)
	at com.qf.etl.mr.tohbase.TohbaseRunner.handleArgs(TohbaseRunner.java:160)
	at com.qf.etl.mr.tohbase.TohbaseRunner.run(TohbaseRunner.java:58)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.qf.etl.mr.tohbase.TohbaseRunner.main(TohbaseRunner.java:39)
Caused by: java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:648)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:744)
	at org.apache.hadoop.ipc.Client$Connection.access$3000(Client.java:396)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1557)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	... 21 more
[druid] 2018-08-17 16:42:08,146 [main           ] INFO  zookeeper.RecoverableZooKeeper {1} - Process identifier=hconnection-0x74bada02 connecting to ZooKeeper ensemble=hadoop701:2181
   [druid] 2018-08-17 16:42:08,213 [main           ] INFO  org.apache.zookeeper.ZooKeeper {1} - Client environment:zookeeper.version=3.4.5-cdh5.13.2--1, built on 02/02/2018 18:46 GMT
   [druid] 2018-08-17 16:42:08,213 [main           ] INFO  org.apache.zookeeper.ZooKeeper {1} - Client environment:host.name=PC201807051736
   [druid] 2018-08-17 16:42:08,213 [main           ] INFO  org.apache.zookeeper.ZooKeeper {1} - Client environment:java.version=1.8.0_162
   [druid] 2018-08-17 16:42:08,214 [main           ] INFO  org.apache.zookeeper.ZooKeeper {1} - Client environment:java.vendor=Oracle Corporation
   [druid] 2018-08-17 16:42:08,214 [main           ] INFO  org.apache.zookeeper.ZooKeeper {1} - Client environment:java.home=D:\java\jdk\Java\jdk1.8.0_162\jre
   [druid] 2018-08-17 16:42:08,214 [main           ] INFO  org.apache.zookeeper.ZooKeeper {1} - Client environment:java.class.path=D:\java\jdk\Java\jdk1.8.0_162\jre\lib\charsets.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\deploy.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\ext\access-bridge-64.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\ext\cldrdata.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\ext\dnsns.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\ext\jaccess.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\ext\jfxrt.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\ext\localedata.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\ext\nashorn.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\ext\sunec.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\ext\sunjce_provider.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\ext\sunmscapi.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\ext\sunpkcs11.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\ext\zipfs.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\javaws.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\jce.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\jfr.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\jfxswt.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\jsse.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\management-agent.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\plugin.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\resources.jar;D:\java\jdk\Java\jdk1.8.0_162\jre\lib\rt.jar;D:\ideaworkspace\gp1707Sdk\target\classes;D:\repository\org\apache\hadoop\hadoop-client\2.6.0-mr1-cdh5.13.2\hadoop-client-2.6.0-mr1-cdh5.13.2.jar;D:\repository\org\apache\hadoop\hadoop-common\2.6.0-cdh5.13.2\hadoop-common-2.6.0-cdh5.13.2.jar;D:\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;D:\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\repository\org\apache\avro\avro\1.7.6-cdh5.13.2\avro-1.7.6-cdh5.13.2.jar;D:\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;D:\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;D:\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;D:\repository\org\apache\curator\curator-recipes\2.7.1\curator-recipes-2.7.1.jar;D:\repository\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\repository\org\apache\htrace\htrace-core4\4.0.1-incubating\htrace-core4-4.0.1-incubating.jar;D:\repository\org\apache\hadoop\hadoop-hdfs\2.6.0-cdh5.13.2\hadoop-hdfs-2.6.0-cdh5.13.2.jar;D:\repository\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\repository\org\apache\hadoop\hadoop-core\2.6.0-mr1-cdh5.13.2\hadoop-core-2.6.0-mr1-cdh5.13.2.jar;D:\repository\hsqldb\hsqldb\1.8.0.10\hsqldb-1.8.0.10.jar;D:\repository\org\apache\hbase\hbase-client\1.2.0-cdh5.13.2\hbase-client-1.2.0-cdh5.13.2.jar;D:\repository\org\apache\hbase\hbase-annotations\1.2.0-cdh5.13.2\hbase-annotations-1.2.0-cdh5.13.2.jar;D:\repository\org\apache\hbase\hbase-common\1.2.0-cdh5.13.2\hbase-common-1.2.0-cdh5.13.2.jar;D:\repository\org\apache\hbase\hbase-protocol\1.2.0-cdh5.13.2\hbase-protocol-1.2.0-cdh5.13.2.jar;D:\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;D:\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;D:\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;D:\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\repository\org\apache\zookeeper\zookeeper\3.4.5-cdh5.13.2\zookeeper-3.4.5-cdh5.13.2.jar;D:\repository\org\apache\htrace\htrace-core\3.2.0-incubating\htrace-core-3.2.0-incubating.jar;D:\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;D:\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;D:\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;D:\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\repository\org\apache\hadoop\hadoop-annotations\2.6.0-cdh5.13.2\hadoop-annotations-2.6.0-cdh5.13.2.jar;D:\repository\org\apache\hadoop\hadoop-auth\2.6.0-cdh5.13.2\hadoop-auth-2.6.0-cdh5.13.2.jar;D:\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\repository\junit\junit\4.12\junit-4.12.jar;D:\repository\org\apache\hbase\hbase-server\1.2.0-cdh5.13.2\hbase-server-1.2.0-cdh5.13.2.jar;D:\repository\org\apache\hbase\hbase-procedure\1.2.0-cdh5.13.2\hbase-procedure-1.2.0-cdh5.13.2.jar;D:\repository\org\apache\hbase\hbase-common\1.2.0-cdh5.13.2\hbase-common-1.2.0-cdh5.13.2-tests.jar;D:\repository\org\apache\hbase\hbase-prefix-tree\1.2.0-cdh5.13.2\hbase-prefix-tree-1.2.0-cdh5.13.2.jar;D:\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\repository\org\apache\hbase\hbase-hadoop-compat\1.2.0-cdh5.13.2\hbase-hadoop-compat-1.2.0-cdh5.13.2.jar;D:\repository\org\apache\hbase\hbase-hadoop2-compat\1.2.0-cdh5.13.2\hbase-hadoop2-compat-1.2.0-cdh5.13.2.jar;D:\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;D:\repository\asm\asm\3.1\asm-3.1.jar;D:\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;D:\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;D:\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\repository\org\mortbay\jetty\jetty\6.1.26.cloudera.4\jetty-6.1.26.cloudera.4.jar;D:\repository\org\mortbay\jetty\jetty-util\6.1.26.cloudera.4\jetty-util-6.1.26.cloudera.4.jar;D:\repository\org\mortbay\jetty\jetty-sslengine\6.1.26.cloudera.4\jetty-sslengine-6.1.26.cloudera.4.jar;D:\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;D:\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;D:\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;D:\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;D:\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;D:\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;D:\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;D:\repository\org\jamon\jamon-runtime\2.4.1\jamon-runtime-2.4.1.jar;D:\repository\com\lmax\disruptor\3.3.0\disruptor-3.3.0.jar;D:\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;D:\repository\org\apache\hadoop\hadoop-hdfs\2.6.0-cdh5.13.2\hadoop-hdfs-2.6.0-cdh5.13.2-tests.jar;D:\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\repository\org\apache\hive\hive-exec\1.1.0-cdh5.13.2\hive-exec-1.1.0-cdh5.13.2.jar;D:\repository\org\apache\hive\hive-ant\1.1.0-cdh5.13.2\hive-ant-1.1.0-cdh5.13.2.jar;D:\repository\org\apache\velocity\velocity\1.5\velocity-1.5.jar;D:\repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\repository\org\apache\hive\hive-metastore\1.1.0-cdh5.13.2\hive-metastore-1.1.0-cdh5.13.2.jar;D:\repository\org\apache\hive\hive-serde\1.1.0-cdh5.13.2\hive-serde-1.1.0-cdh5.13.2.jar;D:\repository\org\apache\hive\hive-common\1.1.0-cdh5.13.2\hive-common-1.1.0-cdh5.13.2.jar;D:\repository\org\apache\commons\commons-lang3\3.1\commons-lang3-3.1.jar;D:\repository\org\eclipse\jetty\aggregate\jetty-all\7.6.0.v20120127\jetty-all-7.6.0.v20120127.jar;D:\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\repository\org\apache\geronimo\specs\geronimo-jta_1.1_spec\1.1.1\geronimo-jta_1.1_spec-1.1.1.jar;D:\repository\javax\mail\mail\1.4.1\mail-1.4.1.jar;D:\repository\javax\activation\activation\1.1\activation-1.1.jar;D:\repository\org\apache\geronimo\specs\geronimo-jaspic_1.0_spec\1.0\geronimo-jaspic_1.0_spec-1.0.jar;D:\repository\org\apache\geronimo\specs\geronimo-annotation_1.0_spec\1.1.1\geronimo-annotation_1.0_spec-1.1.1.jar;D:\repository\asm\asm-commons\3.1\asm-commons-3.1.jar;D:\repository\asm\asm-tree\3.1\asm-tree-3.1.jar;D:\repository\joda-time\joda-time\2.8.1\joda-time-2.8.1.jar;D:\repository\com\codahale\metrics\metrics-core\3.0.2\metrics-core-3.0.2.jar;D:\repository\com\codahale\metrics\metrics-jvm\3.0.2\metrics-jvm-3.0.2.jar;D:\repository\com\codahale\metrics\metrics-json\3.0.2\metrics-json-3.0.2.jar;D:\repository\com\fasterxml\jackson\core\jackson-databind\2.2.2\jackson-databind-2.2.2.jar;D:\repository\com\fasterxml\jackson\core\jackson-annotations\2.2.2\jackson-annotations-2.2.2.jar;D:\repository\com\fasterxml\jackson\core\jackson-core\2.2.2\jackson-core-2.2.2.jar;D:\repository\net\sf\opencsv\opencsv\2.3\opencsv-2.3.jar;D:\repository\com\twitter\parquet-hadoop-bundle\1.5.0-cdh5.13.2\parquet-hadoop-bundle-1.5.0-cdh5.13.2.jar;D:\repository\com\sun\jersey\jersey-servlet\1.14\jersey-servlet-1.14.jar;D:\repository\com\jolbox\bonecp\0.8.0.RELEASE\bonecp-0.8.0.RELEASE.jar;D:\repository\org\apache\derby\derby\10.11.1.1\derby-10.11.1.1.jar;D:\repository\org\datanucleus\datanucleus-api-jdo\3.2.6\datanucleus-api-jdo-3.2.6.jar;D:\repository\org\datanucleus\datanucleus-rdbms\3.2.9\datanucleus-rdbms-3.2.9.jar;D:\repository\commons-pool\commons-pool\1.5.4\commons-pool-1.5.4.jar;D:\repository\commons-dbcp\commons-dbcp\1.4\commons-dbcp-1.4.jar;D:\repository\javax\jdo\jdo-api\3.0.1\jdo-api-3.0.1.jar;D:\repository\javax\transaction\jta\1.1\jta-1.1.jar;D:\repository\org\apache\thrift\libthrift\0.9.3\libthrift-0.9.3.jar;D:\repository\org\apache\hive\hive-shims\1.1.0-cdh5.13.2\hive-shims-1.1.0-cdh5.13.2.jar;D:\repository\org\apache\hive\shims\hive-shims-common\1.1.0-cdh5.13.2\hive-shims-common-1.1.0-cdh5.13.2.jar;D:\repository\org\apache\hive\shims\hive-shims-0.23\1.1.0-cdh5.13.2\hive-shims-0.23-1.1.0-cdh5.13.2.jar;D:\repository\org\apache\hadoop\hadoop-yarn-server-resourcemanager\2.6.0-cdh5.13.2\hadoop-yarn-server-resourcemanager-2.6.0-cdh5.13.2.jar;D:\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;D:\repository\com\google\inject\guice\3.0\guice-3.0.jar;D:\repository\javax\inject\javax.inject\1\javax.inject-1.jar;D:\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;D:\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;D:\repository\org\apache\hadoop\hadoop-yarn-common\2.6.0-cdh5.13.2\hadoop-yarn-common-2.6.0-cdh5.13.2.jar;D:\repository\org\apache\hadoop\hadoop-yarn-api\2.6.0-cdh5.13.2\hadoop-yarn-api-2.6.0-cdh5.13.2.jar;D:\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.0-cdh5.13.2\hadoop-yarn-server-common-2.6.0-cdh5.13.2.jar;D:\repository\org\apache\hadoop\hadoop-yarn-server-applicationhistoryservice\2.6.0-cdh5.13.2\hadoop-yarn-server-applicationhistoryservice-2.6.0-cdh5.13.2.jar;D:\repository\org\apache\hadoop\hadoop-yarn-server-web-proxy\2.6.0-cdh5.13.2\hadoop-yarn-server-web-proxy-2.6.0-cdh5.13.2.jar;D:\repository\org\apache\hive\shims\hive-shims-scheduler\1.1.0-cdh5.13.2\hive-shims-scheduler-1.1.0-cdh5.13.2.jar;D:\repository\org\mockito\mockito-all\1.9.5\mockito-all-1.9.5.jar;D:\repository\org\cloudera\logredactor\logredactor\1.0.3\logredactor-1.0.3.jar;D:\repository\org\codehaus\jackson\jackson-xc\1.8.8\jackson-xc-1.8.8.jar;D:\repository\log4j\apache-log4j-extras\1.2.17\apache-log4j-extras-1.2.17.jar;D:\repository\org\antlr\antlr-runtime\3.4\antlr-runtime-3.4.jar;D:\repository\org\antlr\stringtemplate\3.2.1\stringtemplate-3.2.1.jar;D:\repository\antlr\antlr\2.7.7\antlr-2.7.7.jar;D:\repository\org\antlr\ST4\4.0.4\ST4-4.0.4.jar;D:\repository\org\apache\ant\ant\1.9.1\ant-1.9.1.jar;D:\repository\org\apache\ant\ant-launcher\1.9.1\ant-launcher-1.9.1.jar;D:\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\repository\org\apache\thrift\libfb303\0.9.3\libfb303-0.9.3.jar;D:\repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\repository\org\apache\curator\curator-framework\2.6.0\curator-framework-2.6.0.jar;D:\repository\org\codehaus\groovy\groovy-all\2.4.4\groovy-all-2.4.4.jar;D:\repository\org\datanucleus\datanucleus-core\3.2.10\datanucleus-core-3.2.10.jar;D:\repository\org\apache\calcite\calcite-core\1.0.0-incubating\calcite-core-1.0.0-incubating.jar;D:\repository\org\apache\calcite\calcite-linq4j\1.0.0-incubating\calcite-linq4j-1.0.0-incubating.jar;D:\repository\org\pentaho\pentaho-aggdesigner-algorithm\5.1.5-jhyde\pentaho-aggdesigner-algorithm-5.1.5-jhyde.jar;D:\repository\eigenbase\eigenbase-properties\1.1.4\eigenbase-properties-1.1.4.jar;D:\repository\org\codehaus\janino\janino\2.7.6\janino-2.7.6.jar;D:\repository\org\codehaus\janino\commons-compiler\2.7.6\commons-compiler-2.7.6.jar;D:\repository\org\apache\calcite\calcite-avatica\1.0.0-incubating\calcite-avatica-1.0.0-incubating.jar;D:\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;D:\repository\jline\jline\2.12\jline-2.12.jar;D:\repository\org\slf4j\slf4j-api\1.7.5\slf4j-api-1.7.5.jar;D:\repository\org\slf4j\slf4j-log4j12\1.7.5\slf4j-log4j12-1.7.5.jar;D:\repository\cz\mallat\uasparser\uasparser\0.6.1\uasparser-0.6.1.jar;D:\repository\net\sourceforge\jregex\jregex\1.2_01\jregex-1.2_01.jar;D:\repository\com\alibaba\fastjson\1.2.47\fastjson-1.2.47.jar;D:\java\IntelliJIDEA\lib\idea_rt.jar
   [druid] 2018-08-17 16:42:08,219 [main           ] INFO  org.apache.zookeeper.ZooKeeper {1} - Client environment:java.library.path=D:\java\jdk\Java\jdk1.8.0_162\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\java\jdk\Java\jdk1.8.0_162\bin;D:\java\jdk\Java\jdk1.8.0_162\jre\bin;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\mysql-5.7.21-winx64/bin;D:\java\apache-maven-3.3.9\bin;D:\java\scala-2.10.6/bin;D:\java\elasticsearch-2.4.4/bin;D:\java\Git\cmd;.
   [druid] 2018-08-17 16:42:08,219 [main           ] INFO  org.apache.zookeeper.ZooKeeper {1} - Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\
   [druid] 2018-08-17 16:42:08,219 [main           ] INFO  org.apache.zookeeper.ZooKeeper {1} - Client environment:java.compiler=<NA>
   [druid] 2018-08-17 16:42:08,219 [main           ] INFO  org.apache.zookeeper.ZooKeeper {1} - Client environment:os.name=Windows 7
   [druid] 2018-08-17 16:42:08,219 [main           ] INFO  org.apache.zookeeper.ZooKeeper {1} - Client environment:os.arch=amd64
   [druid] 2018-08-17 16:42:08,219 [main           ] INFO  org.apache.zookeeper.ZooKeeper {1} - Client environment:os.version=6.1
   [druid] 2018-08-17 16:42:08,219 [main           ] INFO  org.apache.zookeeper.ZooKeeper {1} - Client environment:user.name=Administrator
   [druid] 2018-08-17 16:42:08,224 [main           ] INFO  org.apache.zookeeper.ZooKeeper {1} - Client environment:user.home=C:\Users\Administrator
   [druid] 2018-08-17 16:42:08,224 [main           ] INFO  org.apache.zookeeper.ZooKeeper {1} - Client environment:user.dir=D:\ideaworkspace\gp1707Sdk
   [druid] 2018-08-17 16:42:08,226 [main           ] INFO  org.apache.zookeeper.ZooKeeper {1} - Initiating client connection, connectString=hadoop701:2181 sessionTimeout=90000 watcher=hconnection-0x74bada020x0, quorum=hadoop701:2181, baseZNode=/hbase
   [druid] 2018-08-17 16:42:08,325 [hadoop701:2181)] INFO  rg.apache.zookeeper.ClientCnxn {1} - Opening socket connection to server hadoop701/192.168.216.51:2181. Will not attempt to authenticate using SASL (unknown error)
   [druid] 2018-08-17 16:42:09,339 [hadoop701:2181)] WARN  rg.apache.zookeeper.ClientCnxn {1} - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
   java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[druid] 2018-08-17 16:42:10,447 [hadoop701:2181)] INFO  rg.apache.zookeeper.ClientCnxn {1} - Opening socket connection to server hadoop701/192.168.216.51:2181. Will not attempt to authenticate using SASL (unknown error)
   [druid] 2018-08-17 16:42:11,447 [hadoop701:2181)] WARN  rg.apache.zookeeper.ClientCnxn {1} - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
   java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[druid] 2018-08-17 16:42:12,548 [hadoop701:2181)] INFO  rg.apache.zookeeper.ClientCnxn {1} - Opening socket connection to server hadoop701/192.168.216.51:2181. Will not attempt to authenticate using SASL (unknown error)
   [druid] 2018-08-17 16:42:13,549 [hadoop701:2181)] WARN  rg.apache.zookeeper.ClientCnxn {1} - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
   java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[druid] 2018-08-17 16:42:14,651 [hadoop701:2181)] INFO  rg.apache.zookeeper.ClientCnxn {1} - Opening socket connection to server hadoop701/192.168.216.51:2181. Will not attempt to authenticate using SASL (unknown error)
   [druid] 2018-08-17 16:42:15,650 [hadoop701:2181)] WARN  rg.apache.zookeeper.ClientCnxn {1} - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
   java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[druid] 2018-08-17 16:42:16,756 [hadoop701:2181)] INFO  rg.apache.zookeeper.ClientCnxn {1} - Opening socket connection to server hadoop701/192.168.216.51:2181. Will not attempt to authenticate using SASL (unknown error)
   [druid] 2018-08-17 16:42:17,759 [hadoop701:2181)] WARN  rg.apache.zookeeper.ClientCnxn {1} - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
   java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[druid] 2018-08-17 16:42:18,860 [hadoop701:2181)] INFO  rg.apache.zookeeper.ClientCnxn {1} - Opening socket connection to server hadoop701/192.168.216.51:2181. Will not attempt to authenticate using SASL (unknown error)
   [druid] 2018-08-17 16:42:19,872 [hadoop701:2181)] WARN  rg.apache.zookeeper.ClientCnxn {1} - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
   java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[druid] 2018-08-17 16:42:20,973 [hadoop701:2181)] INFO  rg.apache.zookeeper.ClientCnxn {1} - Opening socket connection to server hadoop701/192.168.216.51:2181. Will not attempt to authenticate using SASL (unknown error)
   [druid] 2018-08-17 16:42:21,982 [hadoop701:2181)] WARN  rg.apache.zookeeper.ClientCnxn {1} - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
   java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[druid] 2018-08-17 16:42:23,090 [hadoop701:2181)] INFO  rg.apache.zookeeper.ClientCnxn {1} - Opening socket connection to server hadoop701/192.168.216.51:2181. Will not attempt to authenticate using SASL (unknown error)
   [druid] 2018-08-17 16:42:24,091 [hadoop701:2181)] WARN  rg.apache.zookeeper.ClientCnxn {1} - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
   java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
